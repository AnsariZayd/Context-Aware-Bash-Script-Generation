# Context-Aware-Bash-Script-Generation
The project involves fine-tuning Llama2 a large language model (LLM) for generating bash script code based on user input prompts. The system extracts important details like intent, named entities, and expected output from the prompt and uses them to generate code. The extracted prompt is fed to the model and it generates the code. The generated code is checked for errors by running it in a virtual environment. If errors are found, the code is regenerated until it's error-free. Key considerations include input processing, model fine-tuning, error handling, feedback loop implementation, user interface design, optimization, documentation, and testing.

1.	Automated Scripting: Simplify and automate the generation of complex scripts for system administration or other repetitive tasks.
2.	Education and Training: Provide a learning tool for beginners in programming or scripting by generating code snippets and explanations for different tasks.
3.	Command-Line Interface (CLI) Tool Assistance
4.	Code Documentation: Enhance code documentation by automatically generating code examples and explanations for specific functionalities.
5.	Script Versioning and History: Maintain a history of generated scripts, allowing users to revisit or modify previous code snippets generated by the tool.
6.	Automated Code Testing and Output Verfifcation: Generated code will run a virtual environment and will be checked for errors. Output verification can also be perfomed. (Novelty)
7.	Choose Base Model â€“ Llama2, HuggingFace GPTBigCode, GPT-2 (Considered Models)
8.	Create a dataset using existing resources like Geeks for Geeks tutorials, Linux MAN pages etc. Combine them into User Prompt and Output pairs.
9.	Develop a context based mechanism for follow up prompts
10.	Develop a code execution module to run generated code or user input code and check for compilation errors, runtime errors and verify expected output.
11.	Train the model and optimize hyper parameters
12.	Performance Analysis and Code Review
